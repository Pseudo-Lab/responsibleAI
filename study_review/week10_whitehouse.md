## 2023/10/30 미국 행정 명령, Safe, Secure, and Trustworthy Artificial Intelligence
- 원문 링크 : https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/fact-sheet-president-biden-issues-executive-order-on-safe-secure-and-trustworthy-artificial-intelligence/
- 번역 전문 : [Safe, Secure, and Trustworthy Artificial Intelligence](../translation/safe_secure_and_trustworthy_artificial_intelligence.md)
- AI 안전 및 보안을 위한 새로운 표준
- 미국인의 개인 정보 보호
- 형평성 및 시민권 증진
- 소비자, 환자 및 학생 옹호
- 근로자 지원
- 혁신과 경쟁 촉진
- 해외에서 미국 리더십 발전
- 책임감 있고 효과적인 정부의 AI 사용 보장

## AI 권리장전 청사진, 백악관
- 원문 링크 : https://www.whitehouse.gov/ostp/ai-bill-of-rights/
- 번역 전문 : [Blueprint for an AI Bill of Rights](../translation/blueprint_for_an_ai_bill_of_rights.md)
- 안전하고 효과적인 시스템
- 알고리즘 차별 보호
- 데이터 프라이버시
- 공지 및 설명
- 인간의 대안, 고려 및 대체
- AI 권리 장전에 대한 청사진 적용

## 자유 토론
### 주제 1 : 미국 행정 명령 리뷰
- 관련 링크 1,  톰슨로이터코리아 “2023국내외 AI규제 및 정책 동향” : https://www.thomsonreuters.co.kr/content/dam/ewp-m/documents/korea/ko/pdf/other/lawnb-report-oct-2023.pdf
- 관련 뉴스 1,  “각국의 생성 AI 규제 및 정책 동향” : https://www.2e.co.kr/news/articleView.html?idxno=302827
- 관련 뉴스 2, “[테크톡] 섬뜩한 AI의 편견 “당신은 고릴라입니다” : https://news.kbs.co.kr/news/pc/view/view.do?ncd=5070123
- AI에 대한 이슈들을 포괄적으로 다룬 것이 인상적이었으며 행정 명령 답게 각 기관 및 부처의 역할 및 소임등이 명시된 것 또한 감명 깊었다. 행정 명령이 대중에 공개되었다는 점에서 더 큰 의미를 가질 것으로 보인다. 외부 기업, 단체, 개인이 관련 사업을 하거나 문제를 겪을 때 어느 부처에 도움을 구해야할 지 분명해졌기 때문이고 그로 인해 교류가 증가할 것으로 보이기 때문이다.
- 편견 차별에 대한 내용이 많았던 것 같다. 미국이 다민족, 다인종 국가이기 때문인 것으로 보인다. 자동화된 알고리즘의 인종차별 문제도 미국에서 먼저 대두됐던 것으로 알고 있다.
- 다른 나라의 사례가 궁금하여 찾아보았고 중심 내용만 추려보았다.
    - 미국 : 자국 AI 산업 진흥을 위한 규제
    - 중국 : 사회주의 핵심 가치를 반영, 콘텐츠 및 차별 규제
    - EU : 기업이나 자국 보다는 AI 일반에 대한 규제
    - 국내 : 생성형 AI 에 대한 규제 논의 중

### 주제 2 : 책임 있는 AI
- 관련 뉴스 1, “메타, '책임 있는 AI팀' 해체” : https://zdnet.co.kr/view/?no=20231119085825
- 관련 뉴스 2, “'5일만' 오픈AI 복귀한 샘 알트만⋯ 해고 이유 놓고 '떠들썩’” : https://www.asiatime.co.kr/article/20231123500311#_enliple#_mobwcvr
- 책임 있는 AI, AI 윤리 관련 팀들의 축소 및 해체 소식이 종종 들려 온다. 이번 미국 행정 명령을 보더라도 책임 있는 AI의 중요성이 여느 때보다도 강조되고 있는 현재이지만 현실은 녹록치 않은 것 같다.
- 샘 알트만의 해고 이슈에도 AI 안전 이슈가 엮여있었다. 그 실제 배경은 불분명하지만 “오픈AI 이사회 내에서 기업의 수익성과 빠른 기술개발이 필요하다는 샘 알트만과 인공지능(AI) 개발에 더 많은 안전과 주의를 요구한 이사회 다수가 충돌해왔다”고 하였다. AI 위협과 안전 문제는 앞으로도 뜨거운 감자가 될 것으로 보인다.