## The Bletchley Declaration 번역 전문

인공 지능(AI)은 엄청난 글로벌 기회를 제시합니다. 인공 지능은 인류의 복지, 평화, 번영을 변화시키고 향상시킬 수 있는 잠재력을 가지고 있습니다. 이를 실현하기 위해 우리는 AI가 인간 중심적이고 신뢰할 수 있으며 책임감 있는 방식으로 안전한 방식으로 설계, 개발, 배포 및 사용(designed, developed, deployed, and use)되어야 함을 확인합니다. 우리는 포용적인 경제 성장, 지속 가능한 발전과 혁신을 촉진하고, 인권과 기본적 자유를 보호하고, AI 시스템의 잠재력을 완전히 실현하기 위해 대중의 신뢰와 확신을 조성한 AI에 대한 협력에 대한 지금까지의 국제 사회의 노력을 환영합니다.

AI 시스템은 이미 주택, 고용, 교통, 교육, 건강, 접근성, 정의 등 일상생활의 다양한 영역에 걸쳐 배포되어 있으며 그 활용도는 더욱 늘어날 것으로 예상됩니다. 따라서 우리는 지금이 AI의 안전한 개발과 AI의 변혁적 기회가 국가와 전 세계에서 포용적인 방식으로 선과 모두를 위해 사용될 필요성을 행동하고 확인해야 할 특별한 순간임을 인식합니다. 여기에는 보건, 교육, 식량안보, 과학, 청정 에너지, 생물다양성, 기후 등의 공공 서비스, 인권 향유 실현, 유엔 지속가능발전목표 달성을 위한 노력 강화 등이 포함됩니다.

이러한 기회 외에도 AI는 일상 생활 영역을 포함하여 상당한 위험을 초래합니다. 이를 위해 우리는 기존 포럼 및 기타 관련 이니셔티브에서 AI 시스템의 잠재적 영향을 조사하고 해결하기 위한 관련 국제적 노력과 인권 보호, 투명성 및 설명 가능성, 공정성, 책임, 규제, 안전, 적절한 인간의 감독, 윤리, 편견 완화, 개인 정보 보호 및 해결되어야 할 데이터 보호 등에 대한 인식을 환영합니다. 또한 콘텐츠를 조작하거나 사기성 콘텐츠를 생성하는 능력으로 인해 예상치 못한 위험이 발생할 가능성이 있다는 점에도 주목합니다. 이러한 모든 문제는 매우 중요하며 우리는 이러한 문제를 해결해야 할 필요성과 시급성을 확인합니다.

특정 안전 위험은 (물론 관련된 특정 좁은 AI 또한 피해를 초래할 수 있는 능력을 보일 수 있지만) 오늘날의 가장 고도화된 모델의 현재 기능과 일치하거나 초과하는 다양한 범주의 작업을 수행할 수 있는 파운데이션 모델을 포함한 매우 유능한 범용 AI 모델로 이해되는 AI의 ‘프론티어’에서 발생합니다.  오늘날 가장 발전된 모델에 존재하는 기능과 일치하거나 그 이상입니다. 잠재적인 의도적 오용이나 인간 의도와의 일치와 관련된 의도하지 않은 통제 문제로 인해 상당한 위험이 발생할 수 있습니다. 이러한 문제는 부분적으로 해당 기능을 완전히 이해하지 못해 예측하기 어렵기 때문에 발생합니다. 우리는 특히 사이버 보안, 생명공학과 같은 영역의 위험과 최첨단 AI 시스템이 허위 정보와 같은 위험을 증폭시킬 수 있는 분야에 대해 우려하고 있습니다. 이러한 AI 모델의 가장 중요한 기능으로 인해 고의적이든 의도적이지 않든 심각하고 심지어 재앙적인 피해를 입힐 가능성이 있습니다. AI의 빠르고 불확실한 변화 속도와 기술에 대한 투자가 가속화되는 상황에서 우리는 이러한 잠재적 위험과 이를 해결하기 위한 조치에 대한 깊은 이해가 특히 시급하다고 확신합니다.

AI로 인해 발생하는 많은 위험은 본질적으로 국제적이므로 국제 협력을 통해 가장 잘 해결됩니다. 우리는 AI로 인해 발생하는 광범위한 위험을 해결하기 위한 협력을 촉진하기 위해 안전하고 기존 국제 포럼 및 기타 관련 이니셔티브를 통해 모두의 이익을 지원하는 포용적인 방식으로 협력하여 인간 중심적이고 신뢰할 수 있으며 책임감 있는 AI를 보장하기 위해 결의합니다. 그렇게 함으로써 우리는 국가들이 AI와 관련된 위험을 고려하고 이점을 극대화하는 혁신 지향, 비례적인 거버넌스 및 규제 접근 방식의 중요성을 고려해야 함을 인식합니다. 여기에는 적절한 경우 국가 상황과 적용 가능한 법적 체계를 기반으로 위험을 분류하고 범주화하는 것이 포함될 수 있습니다. 우리는 또한 적절한 경우 공통 원칙 및 행동 강령과 같은 접근 방식에 대한 협력의 관련성에 주목합니다. 프론티어 AI와 관련하여 발견될 가능성이 가장 높은 특정 위험과 관련하여 우리는 미래의 국제 AI 안전 서밋을 포함하여, 기존 국제 포럼 및 기타 관련 이니셔티브를 통해 협력을 강화 및 유지하고 더 많은 국가와 협력을 확대하여 식별하고 이해하며 적절한 조치를 취할 것을 결의합니다.

모든 행위자는 AI의 안전을 보장하는 데 역할이 있습니다. 국가, 국제 포럼 및 기타 이니셔티브, 기업, 시민 사회 및 학계가 함께 협력해야 합니다. 포괄적인 AI의 중요성을 인식하고 디지털 격차를 해소하면서, 우리는 국제 협력이 적절한 경우 광범위한 파트너를 참여시키고 참여시키기 위해 노력해야 함을 재확인하며, 개발도상국이 AI 역량 구축 및 활용을 강화하는 데 도움이 될 수 있는 개발 지향적 접근 방식과 정책을 환영합니다. 그리고 지속 가능한 성장을 지원하고 개발 격차를 해소하기 위한 AI의 역할을 지원합니다.

우리는 AI 수명주기 전반에 걸쳐 안전을 고려해야 하지만, 최첨단 AI 기능, 특히 매우 강력하고 잠재적으로 유해한 AI 시스템을 개발하는 행위자는 안전 테스트을 위한 시스템을 포함하여, 평가 및 기타 적절한 조치를 통해 이러한 AI 시스템의 안전을 보장할 특히 강력한 책임이 있음을 확인합니다. 우리는 모든 관련 행위자가 특히 오용과 통제 문제 및 기타 위험의 증폭을 방지하기 위해 잠재적으로 유해한 기능과 나타날 수 있는 관련 효과를 측정, 모니터링 및 완화하기 위한 계획에 대해 상황에 맞는 투명성과 책임성을 제공할 것을 권장합니다.

협력의 맥락에서 국내 및 국제 수준의 조치를 알리기 위해 최첨단 AI 위험을 해결하기 위한 우리의 의제는 다음 사항에 중점을 둘 것입니다.

- AI가 우리 사회에 미치는 영향을 이해하기 위한 보다 폭넓은 글로벌 접근 방식의 맥락에서 공통 관심사인 AI 안전 위험을 식별하고, 이러한 위험에 대한 공유된 과학적, 증거 기반 이해를 구축하고, 역량이 지속적으로 증가함에 따라 이러한 이해를 유지합니다.
- 그러한 위험에 비추어 안전을 보장하기 위해 국가 전체에 걸쳐 각각의 위험 기반 정책을 구축하고, 국가 상황과 적용 가능한 법적 틀에 따라 우리의 접근 방식이 다를 수 있다는 점을 인식하면서 적절하게 협력합니다. 여기에는 최첨단 AI 기능을 개발하는 민간 행위자의 투명성 향상, 적절한 평가 지표, 안전 테스트 도구, 관련 공공 부문 역량 및 과학 연구 개발이 포함됩니다.

이 의제의 조성에 대하여 정책 입안 및 공익을 위해 이용 가능한 최고의 과학 제공을 촉진하기 위해 우리는 기존 국제 포럼 및 기타 관련 이니셔티브를 포함하여 기존 및 새로운 다자, 복수 및 양자 협력을 포괄하고 보완하는 프론티어 AI 안전에 대한 국제적으로 포용적인 과학 연구 네트워크를 지원하기로 결의합니다.

AI의 변혁적이고 긍정적인 잠재력을 인식하고 AI에 대한 더 넓은 국제 협력을 보장하는 일환으로 우리는 기존 국제 포럼 및 기타 관련 이니셔티브를 참여시키고 더 넓은 국제 논의에 개방적인 방식으로 기여하는 포괄적인 글로벌 대화를 유지하기로 결의하며 기술의 이점이 공공선과 모두를 위해 책임감 있게 활용될 수 있도록 최첨단 AI 안전에 대한 연구를 계속합니다. 2024년에 다시 만나기를 기대합니다.